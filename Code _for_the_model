!pip install tensorflow

# MOUNTING THE GOOGLE DRIVE FOR DATA TRANSFER
from google.colab import drive
drive.mount('/content/drive')

# IMPORTING ALL THE LIBERARIES FOR THE PROJECT
import zipfile
import os
import cv2
import random
import shutil
import pandas as pd
import imageio
import plotly.graph_objects as go
import plotly.express as px
import plotly.figure_factory as ff
from plotly.subplots import make_subplots
from collections import Counter
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

import tensorflow as tf
import keras
from keras.models import Model
from keras.optimizers import Adam
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization
from sklearn.model_selection import train_test_split

# EXTRACTING DATA FROM THE ZIP FILE
zip_ref = zipfile.ZipFile('/content/drive/MyDrive/Dataset.zip', 'r')
zip_ref.extractall('/content')
zip_ref.close()
os.listdir('/content/Dataset')


# CREATING DIFFERENT DIRECTORIES FOR THE DATASET
directories = {
    'COVID_CT': '/content/Dataset/COVID2_CT',
    'Lung_cancer': '/content/Dataset/Lung cancer',
    'Normal_CT': '/content/Dataset/Normal_CT',
    'Pneumonia_CT': '/content/Dataset/pneumonia_CT'
}


base_dir = '/content/Dataset_split'
train_dir = os.path.join(base_dir, 'train')
test_dir = os.path.join(base_dir, 'test')

for category in directories.keys():
    os.makedirs(os.path.join(train_dir, category), exist_ok=True)
    os.makedirs(os.path.join(test_dir, category), exist_ok=True)


split_ratio = 0.8

for category, source_dir in directories.items():
    images = [f for f in os.listdir(source_dir) if os.path.isfile(os.path.join(source_dir, f))]
    train_images, test_images = train_test_split(images, test_size=1 - split_ratio, random_state=42)


    for image in train_images:
        src_path = os.path.join(source_dir, image)
        dest_path = os.path.join(train_dir, category, image)
        shutil.copy(src_path, dest_path)


    for image in test_images:
        src_path = os.path.join(source_dir, image)
        dest_path = os.path.join(test_dir, category, image)
        shutil.copy(src_path, dest_path)

def count_images_in_directory(directory):
    category_counts = {}
    for category in os.listdir(directory):
        category_path = os.path.join(directory, category)
        if os.path.isdir(category_path):
            images = [img for img in os.listdir(category_path) if os.path.isfile(os.path.join(category_path, img))]
            category_counts[category] = len(images)
    return category_counts


# DATA DIVISION INTO TRAINING AND TESTING DATASETS
def find_image_overlap(train_dir, test_dir):
    overlaps = {}
    for category in os.listdir(train_dir):
        train_category_path = os.path.join(train_dir, category)
        test_category_path = os.path.join(test_dir, category)

        if os.path.isdir(train_category_path) and os.path.isdir(test_category_path):
            train_images = set(os.listdir(train_category_path))
            test_images = set(os.listdir(test_category_path))
            overlap = train_images.intersection(test_images)
            overlaps[category] = list(overlap)
    return overlaps


train_counts = count_images_in_directory(train_dir)
test_counts = count_images_in_directory(test_dir)


overlaps = find_image_overlap(train_dir, test_dir)


print("Training Data:")
for category, count in train_counts.items():
    print(f"{category}: {count} images")

print("\nTesting Data:")
for category, count in test_counts.items():
    print(f"{category}: {count} images")

categories = list(directories.keys())
for i in categories:
    path = os.path.join(train_dir, i)
    for file in os.listdir(path):
        filepath = os.path.join(path, file)
        print(i)
        img = cv2.imread(filepath, 0)
        plt.imshow(img, cmap='gray')
        plt.show()
        break


# IMAGES RESIZING FOR THE MODEL
img_size = 256
data = []

category_dirs = {category: os.path.join(train_dir, category) for category in categories}

for category in categories:
    path = category_dirs[category]
    class_num = categories.index(category)
    for file in os.listdir(path):
        filepath = os.path.join(path, file)
        img = cv2.imread(filepath, 0)
        if img is not None:
            img = cv2.resize(img, (img_size, img_size))
            data.append([img, class_num])

random.shuffle(data)

X, y = [], []
for feature, label in data:
    X.append(feature)
    y.append(label)

X = np.array(X).reshape(-1, img_size, img_size, 1)
y = np.array(y)

X = X / 255.0

print('X length:', len(X))
print('y counts:', Counter(y))


# SEQUENTIAL MODEL WHICH INCLUDE 5 LAYERS
model1 = Sequential()

model1.add(Conv2D(64, (3, 3), activation='relu', input_shape=(img_size, img_size, 1)))
model1.add(MaxPooling2D())

model1.add(Conv2D(64, (3, 3), activation='relu'))
model1.add(MaxPooling2D())

model1.add(Flatten())
model1.add(Dense(16))
model1.add(Dense(4, activation='softmax'))

model1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

model1.summary()


logdir = 'logs'
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)
hist = model1.fit(X, y, batch_size=32, epochs=3, validation_split=0.1, callbacks=[tensorboard_callback])
hist.history


# TESTING DATASET
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import load_model
import os

img_size = 256

test_datagen = ImageDataGenerator(rescale=1./255)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(img_size, img_size),
    color_mode='grayscale',
    class_mode='sparse',
    batch_size=32,
    shuffle=False,
    classes=categories
)

test_loss, test_accuracy = model1.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)


print(f'Test Accuracy: {test_accuracy*100:.2f}%')
print(f'Test Loss: {test_loss:.4f}')


#FINAL RESULTS USING PLOTTING METHODS
plt.figure(figsize=(10, 5))
plt.plot(hist.history['accuracy'], label='Training Accuracy', marker='o')
plt.plot(hist.history['val_accuracy'], label='Validation Accuracy', marker='o')
plt.axhline(y=test_accuracy, color='r', linestyle='--', label=f'Test Accuracy: {test_accuracy*100:.2f}%')
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epochs')
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 5))
plt.plot(hist.history['loss'], label='Training Loss', marker='o')
plt.plot(hist.history['val_loss'], label='Validation Loss', marker='o')
plt.axhline(y=test_loss, color='r', linestyle='--', label=f'Test Loss: {test_loss:.4f}')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.legend()
plt.grid(True)
plt.show()
